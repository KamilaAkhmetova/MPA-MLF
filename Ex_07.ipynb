{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KamilaAkhmetova/MPA-MLF/blob/main/Ex_07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9457fdc4-1690-4c41-8e88-1597fc2a687c",
      "metadata": {
        "id": "9457fdc4-1690-4c41-8e88-1597fc2a687c"
      },
      "source": [
        " # MKA-MLF, Lab_07 Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94e81ae9-825c-4132-97e6-7d19b1dcfd82",
      "metadata": {
        "id": "94e81ae9-825c-4132-97e6-7d19b1dcfd82"
      },
      "source": [
        "## Exercise - XOR Gate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffa6be62-ed89-4801-b297-f1a1211ce297",
      "metadata": {
        "id": "ffa6be62-ed89-4801-b297-f1a1211ce297"
      },
      "source": [
        "## Exercise - Hand-written digits recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89808395-7ffe-4df1-91e5-f31ce090b932",
      "metadata": {
        "id": "89808395-7ffe-4df1-91e5-f31ce090b932"
      },
      "source": [
        "Create CNN which will process and recognize handwritten digits. For this purposes please use the MNIST database (Modified National Institute of Standards and Technology database) which is a large database of handwritten digits that is commonly used for training various image processing systems.\n",
        "\n",
        "The datasample of the MNIST datasets can be see in the following picture"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c65f181-d971-4f0e-ba63-17c242a65d6c",
      "metadata": {
        "id": "0c65f181-d971-4f0e-ba63-17c242a65d6c"
      },
      "source": [
        "### Task description"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b6b04cf-eeec-404a-824b-f9aa1d3b7d7a",
      "metadata": {
        "id": "1b6b04cf-eeec-404a-824b-f9aa1d3b7d7a"
      },
      "source": [
        "In the terms of machine learning, the Hand-written digits recognition can be threated as a multi-class classification problem. This is very important knowledge to structure our model in the correct way (Especially the output-layer, including the number of neurons and activations function and the overall loss function and classification metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b724de14-3931-4983-b443-7e0106d190dc",
      "metadata": {
        "id": "b724de14-3931-4983-b443-7e0106d190dc"
      },
      "source": [
        "### 0. Import libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ffd9b11-f9c1-4b3f-8dd1-cbb18487a075",
      "metadata": {
        "id": "1ffd9b11-f9c1-4b3f-8dd1-cbb18487a075"
      },
      "source": [
        "Import the all necessary libraries, you can get inspired by the previous exercises. You can improst the libraries gradually, when do you progressing with the task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f692dd4-0262-4e7a-b029-69d8280f14d2",
      "metadata": {
        "id": "1f692dd4-0262-4e7a-b029-69d8280f14d2"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "###################################\n",
        "# Write your own code here #\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import SGD\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.regularizers import l1_l2\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "###################################\n",
        "font = {'weight' : 'bold',\n",
        "        'size'   : 12}\n",
        "\n",
        "matplotlib.rc('font', **font)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c4af957-fee1-4806-9d68-797d74c332df",
      "metadata": {
        "id": "9c4af957-fee1-4806-9d68-797d74c332df"
      },
      "source": [
        "### 1. Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33cf2443-c2ed-4aaa-9b10-fa598a4fb6cb",
      "metadata": {
        "id": "33cf2443-c2ed-4aaa-9b10-fa598a4fb6cb"
      },
      "source": [
        "#### 1.1 Load Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd860d81-ab4d-48d2-a071-e0e8aec8000f",
      "metadata": {
        "id": "dd860d81-ab4d-48d2-a071-e0e8aec8000f"
      },
      "source": [
        "You can load the dataset using the following code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b6f52dc-788b-4481-95f2-c4de31cae037",
      "metadata": {
        "id": "1b6f52dc-788b-4481-95f2-c4de31cae037"
      },
      "outputs": [],
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "LLLi14YujK5E"
      },
      "id": "LLLi14YujK5E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "id": "Dn6Ccm_KjOXP"
      },
      "id": "Dn6Ccm_KjOXP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "853727ee-5836-4345-84dd-b0135b33e6d3",
      "metadata": {
        "id": "853727ee-5836-4345-84dd-b0135b33e6d3"
      },
      "source": [
        "#### 1.2 Dataset examination"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93e9f48e-3192-494a-9b0f-e2f66a7c286e",
      "metadata": {
        "id": "93e9f48e-3192-494a-9b0f-e2f66a7c286e"
      },
      "source": [
        "Using the following code, display random images,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "522d7c5e-f50b-46d0-b79d-799d40ff2f1e",
      "metadata": {
        "id": "522d7c5e-f50b-46d0-b79d-799d40ff2f1e"
      },
      "outputs": [],
      "source": [
        "def display_random_images(x_data: np.array, y_data: np.array, count: int = 10) -> None:\n",
        "  index = np.array(len(x_data))\n",
        "  selected_ind = np.random.choice(index, count)\n",
        "\n",
        "  selected_img = x_data[selected_ind]\n",
        "  selected_labels = y_data[selected_ind]\n",
        "  concat_img = np.concatenate(selected_img, axis=1)\n",
        "\n",
        "  plt.figure(figsize=(20,10))\n",
        "  plt.imshow(concat_img, cmap=\"gray\")\n",
        "\n",
        "  for id_label, label in enumerate(selected_labels):\n",
        "    plt.text(14 + 28*id_label, 28*(5/4), label)\n",
        "  plt.axis('off')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "452ea9c5-8438-4b10-8a0e-ef0e418ba5a0",
      "metadata": {
        "id": "452ea9c5-8438-4b10-8a0e-ef0e418ba5a0"
      },
      "outputs": [],
      "source": [
        "display_random_images(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c0e3651-3921-4485-bdae-3731afcf03a2",
      "metadata": {
        "id": "6c0e3651-3921-4485-bdae-3731afcf03a2"
      },
      "source": [
        "Examine the dataset. Answer for yourself the following questions:\n",
        "\n",
        "- What kind of data occurs in our dataset?\n",
        "- How many data samples do we have in train and test datasets?\n",
        "- How many colour channels does the input variable have?\n",
        "- What is the size of the input images?\n",
        "- What is the necessary preprocessing of the input data X?\n",
        "- How many classes do we have in target varoable?\n",
        "- What is the necessary preprocessing of target variable y?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1\n",
        "#  images of digits (mnist)"
      ],
      "metadata": {
        "id": "9g_V_H6x99d_"
      },
      "id": "9g_V_H6x99d_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2\n",
        "# 60000 in the train and 10000 in the test\n",
        "X_train.shape[0]\n",
        "X_test.shape[0]"
      ],
      "metadata": {
        "id": "hwdS453UjA2o"
      },
      "id": "hwdS453UjA2o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3\n",
        "# 1 channel\n",
        "\n"
      ],
      "metadata": {
        "id": "gIcKmsyhkMuY"
      },
      "id": "gIcKmsyhkMuY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4\n",
        "#  the size of the input images is 28, 28\n",
        "X_train.shape[1:]\n",
        "X_test.shape[1:]"
      ],
      "metadata": {
        "id": "E1IbTrI7kRSS"
      },
      "id": "E1IbTrI7kRSS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5\n",
        "# normalization(next task) and reshaping"
      ],
      "metadata": {
        "id": "ZXuqOQNs-1dK"
      },
      "id": "ZXuqOQNs-1dK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6\n",
        "# 10 different classes since we have digits from 0 to 9"
      ],
      "metadata": {
        "id": "ORMAk8eV_SHj"
      },
      "id": "ORMAk8eV_SHj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7\n",
        "# one hot encodint(to_categorical)"
      ],
      "metadata": {
        "id": "jMonK42r_ZMG"
      },
      "id": "jMonK42r_ZMG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "08273dd4-05d0-4cd8-b989-eca8a4d1328a",
      "metadata": {
        "id": "08273dd4-05d0-4cd8-b989-eca8a4d1328a"
      },
      "source": [
        "#### 1.3 Dataset preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c16ee55-312f-4ee5-86cd-e09426e16e82",
      "metadata": {
        "id": "2c16ee55-312f-4ee5-86cd-e09426e16e82"
      },
      "source": [
        "Perform the necessary data preprocessing. The best way to preprocess the data would be one hot encoding for the target variable and normalization for the input variable (using min-max or z-score normalization)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing\n",
        "X_train= X_train.astype('float32') / 255.0\n",
        "X_test= X_test.astype('float32') / 255.0\n",
        "X_train = X_train.reshape(-1, 28, 28, 1)\n",
        "X_test = X_test.reshape(-1, 28, 28, 1)\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n"
      ],
      "metadata": {
        "id": "PjXq41xukhPh"
      },
      "id": "PjXq41xukhPh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_train_encoded = to_categorical(y_train, num_classes=10)"
      ],
      "metadata": {
        "id": "QBABmudCl5E2"
      },
      "id": "QBABmudCl5E2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d20d5fef-cbca-48a2-844f-c9638f0b6bf9",
      "metadata": {
        "id": "d20d5fef-cbca-48a2-844f-c9638f0b6bf9"
      },
      "source": [
        "### 2. Build the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = Sequential()\n",
        "# model.add(Conv2D(32,kernel_size=(3,3), activation='relu'))\n",
        "# model.add(MaxPooling2D(pool_size = 2))\n",
        "\n",
        "# model.add(Flatten(input_shape=(28, 28, 1)))\n",
        "# model.add(Dense(128, activation='sigmoid'))\n",
        "# model.add(Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "8sk33jnrnDXK"
      },
      "id": "8sk33jnrnDXK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "0ffd3896-079e-4758-9579-387f33af9691",
      "metadata": {
        "id": "0ffd3896-079e-4758-9579-387f33af9691"
      },
      "source": [
        "#### 2.1 Define the model structure"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea554fcf-7acd-4453-b18d-b4982f6a10eb",
      "metadata": {
        "id": "ea554fcf-7acd-4453-b18d-b4982f6a10eb"
      },
      "source": [
        "In this section, your task will be to define the model architecture. The intial structure can be defined as follows:\n",
        "\n",
        "Input_layer -> Convolutional_layer(kernel_size=(3,3), no_channels=32) -> Maxpooling_layer(kernel_size=(2, 2)) -> Flatten_layer -> Dense_layer (num_classes)\n",
        "    \n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32,kernel_size=(3,3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "xCGM7lSbB8_I"
      },
      "id": "xCGM7lSbB8_I",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "fde4b3eb-90e1-4724-89df-0db1872560d4",
      "metadata": {
        "id": "fde4b3eb-90e1-4724-89df-0db1872560d4"
      },
      "source": [
        "#### 2.2 Compile the model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a467f8fb-8bfc-4cd4-9eee-820c1b9b5a52",
      "metadata": {
        "id": "a467f8fb-8bfc-4cd4-9eee-820c1b9b5a52"
      },
      "source": [
        "Build the model, use the relevant metrics, optimizer and loss function. While choosing the metrics and loss function, consider fact that we are are trying to solve the multiclass classification problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6d1a924-9e2f-4ca2-b4d6-4724f51ae065",
      "metadata": {
        "id": "e6d1a924-9e2f-4ca2-b4d6-4724f51ae065"
      },
      "outputs": [],
      "source": [
        "loss = None\n",
        "optimizer = None\n",
        "metrics = None\n",
        "learning_rate = 0.0\n",
        "\n",
        "###################################\n",
        "# Write your own code here #\n",
        "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "\n",
        "\n",
        "###################################\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f146b70f-2e8c-484f-abfd-6fc4a8b8177b",
      "metadata": {
        "id": "f146b70f-2e8c-484f-abfd-6fc4a8b8177b"
      },
      "source": [
        "### 3. Training stage"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb1de787-9e40-47e2-bc54-44ccd1864357",
      "metadata": {
        "id": "cb1de787-9e40-47e2-bc54-44ccd1864357"
      },
      "source": [
        "#### 3.1 Model training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b9c7722-aed7-4b2d-a292-572921f0734b",
      "metadata": {
        "id": "2b9c7722-aed7-4b2d-a292-572921f0734b"
      },
      "source": [
        "train your model, define the relevant hyperparameters (no. epochs, batch_size), use 20p of the training data for validation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# history = model.fit(X_train, y_train_encoded, epochs=5, batch_size=128, validation_split = 0.2)"
      ],
      "metadata": {
        "id": "M0g0p1e-oTL_"
      },
      "id": "M0g0p1e-oTL_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=20, batch_size=128, validation_data = (X_test, y_test), verbose = 2)"
      ],
      "metadata": {
        "id": "2q8ofKITDEGz"
      },
      "id": "2q8ofKITDEGz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "45651f2d-5cc4-4896-8edc-f58b50fed605",
      "metadata": {
        "id": "45651f2d-5cc4-4896-8edc-f58b50fed605"
      },
      "source": [
        "#### 3.1 Model Evaluation on validation data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print(f'Test accuracy: {score[1]*100} %')"
      ],
      "metadata": {
        "id": "j8LuaC6fooon"
      },
      "id": "j8LuaC6fooon",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "eb4ea2f2-fcc8-4308-82f6-3dbd5857e989",
      "metadata": {
        "id": "eb4ea2f2-fcc8-4308-82f6-3dbd5857e989"
      },
      "source": [
        "Plot the development of the training and validation loss, and training and validation metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "841d1e30-e448-4b53-b3fc-9b97863391bb",
      "metadata": {
        "id": "841d1e30-e448-4b53-b3fc-9b97863391bb"
      },
      "outputs": [],
      "source": [
        "###################################\n",
        "# Write your own code here #\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "###################################"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22cd86fb-6b4c-4299-a077-fec0ab62464c",
      "metadata": {
        "id": "22cd86fb-6b4c-4299-a077-fec0ab62464c"
      },
      "source": [
        "### 4. Model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d93b7ad-3416-451d-8762-968f4cf1dd13",
      "metadata": {
        "id": "9d93b7ad-3416-451d-8762-968f4cf1dd13"
      },
      "source": [
        "Evaluate the model on the testing dataset using the relevant metrics. Use the confusion metrics as the one of the metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8134b757-aca1-4a0d-a0d2-3a3d0daa8d38",
      "metadata": {
        "id": "8134b757-aca1-4a0d-a0d2-3a3d0daa8d38"
      },
      "outputs": [],
      "source": [
        "###################################\n",
        "# Write your own code here #\n",
        "labels = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "y_pred_classes = np.argmax(y_pred, 1)\n",
        "y_true = np.argmax(y_test, 1)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred_classes)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt = 'd', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('True Values');\n",
        "plt.show();\n",
        "\n",
        "###################################"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44a3f72d-1d76-4d98-9f03-1f8293ed6ad6",
      "metadata": {
        "id": "44a3f72d-1d76-4d98-9f03-1f8293ed6ad6"
      },
      "source": [
        "### 5. Hyperparameter tunning and regularization techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6140057-ce25-4e97-ae7b-81a47a30bebc",
      "metadata": {
        "id": "e6140057-ce25-4e97-ae7b-81a47a30bebc"
      },
      "source": [
        "When your code is ready and fully functional, try several changes in the hyperparameters and see how they influence the testing metrics. Try changes in the network structure. You can also try adding regularization techniques such as L1, L2, and Dropout. Based on the development of training and validation loss, try to identify overfitting and avoid it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1f4b10b-7487-45f4-8702-267715e4041c",
      "metadata": {
        "id": "f1f4b10b-7487-45f4-8702-267715e4041c"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32,kernel_size=(3,3), activation='relu', input_shape=(28, 28, 1), kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)), Dropout(0.25))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "1kkjPxYuyGet"
      },
      "id": "1kkjPxYuyGet",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=20, batch_size=128, validation_data = (X_test, y_test), verbose = 2)"
      ],
      "metadata": {
        "id": "jV9qNzBPyWbi"
      },
      "id": "jV9qNzBPyWbi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print(f'Test accuracy: {score[1]*100:.2f}%')"
      ],
      "metadata": {
        "id": "ArccwKkA5uCT"
      },
      "id": "ArccwKkA5uCT",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}